{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T15:05:50.758459Z",
     "start_time": "2025-03-22T15:04:41.422348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "################################################################################\n",
    "# 1. Environment Setup\n",
    "################################################################################\n",
    "\n",
    "# Replace this with your actual Google Generative AI key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBTpM1obfZC1LV8f7bc99_cpAs7_JHOMRY\"\n",
    "\n",
    "# Initialize the Google Generative AI LLM\n",
    "llm = GoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro-latest\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "################################################################################\n",
    "# 2. Load Models & Data\n",
    "################################################################################\n",
    "\n",
    "# 2.1 Load LabelEncoder for Intent Recognition\n",
    "label_encoder = joblib.load('models/Model training/Intent recognition/label_encoder.pkl')\n",
    "\n",
    "# 2.2 Load Fine-Tuned BERT Model & Tokenizer for Intent Recognition\n",
    "intent_model = BertForSequenceClassification.from_pretrained('intent_recognition_bert')\n",
    "intent_tokenizer = BertTokenizer.from_pretrained('intent_recognition_bert')\n",
    "\n",
    "# 2.3 Load Sentiment Analysis Model & Tokenizer\n",
    "sentiment_model_path = r\"C:\\Users\\LENOVO\\Desktop\\Projects\\SwiftAssist-AI\\SwiftAssist-AI\\contentsentiment_model\"\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_path)\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_path)\n",
    "sentiment_model.to(device)\n",
    "\n",
    "# 2.4 Load SentenceTransformer for FAQ embeddings\n",
    "faq_encoder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# 2.5 Load Preprocessed FAQ Data (with embeddings)\n",
    "D_emb = pd.read_csv('data/FAQ Answering/Preprocessed embedding/D_emb.csv')\n",
    "D_emb[\"embedding\"] = D_emb[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "################################################################################\n",
    "# 3. Supporting Dictionaries & Lists\n",
    "################################################################################\n",
    "\n",
    "# Mapping dictionary for intent labels -> readable strings\n",
    "intent_label_mapping = {\n",
    "    'playmusic': 'Play Music',\n",
    "    'addtoplaylist': 'Add to Playlist',\n",
    "    'ratebook': 'Rate Book',\n",
    "    'searchscreeningevent': 'Search Screening Event',\n",
    "    'bookrestaurant': 'Book Restaurant',\n",
    "    'getweather': 'Get Weather',\n",
    "    'searchcreativework': 'Search Creative Work',\n",
    "    'greeting': 'Greeting',\n",
    "    'greetingresponse': 'Greeting Response',\n",
    "    'courtesygreeting': 'Courtesy Greeting',\n",
    "    'courtesygreetingresponse': 'Courtesy Greeting Response',\n",
    "    'currenthumanquery': 'Current Human Query',\n",
    "    'namequery': 'Name Query',\n",
    "    'realnamequery': 'Real Name Query',\n",
    "    'timequery': 'Time Query',\n",
    "    'thanks': 'Thanks',\n",
    "    'nottalking2u': 'Not Talking to You',\n",
    "    'understandquery': 'Understand Query',\n",
    "    'shutup': 'Shut Up',\n",
    "    'swearing': 'Swearing',\n",
    "    'goodbye': 'Goodbye',\n",
    "    'courtesygoodbye': 'Courtesy Goodbye',\n",
    "    'whoami': 'Who Am I',\n",
    "    'clever': 'Clever',\n",
    "    'gossip': 'Gossip',\n",
    "    'jokes': 'Jokes',\n",
    "    'podbaydoor': 'Pod Bay Door',\n",
    "    'podbaydoorresponse': 'Pod Bay Door Response',\n",
    "    'selfaware': 'Self Aware',\n",
    "    'cancelorder': 'Cancel Order',\n",
    "    'changeorder': 'Change Order',\n",
    "    'changeshippingaddress': 'Change Shipping Address',\n",
    "    'checkcancellationfee': 'Check Cancellation Fee',\n",
    "    'checkinvoice': 'Check Invoice',\n",
    "    'checkpaymentmethods': 'Check Payment Methods',\n",
    "    'checkrefundpolicy': 'Check Refund Policy',\n",
    "    'complaint': 'Complaint',\n",
    "    'contactcustomerservice': 'Contact Customer Service',\n",
    "    'contacthumanagent': 'Contact Human Agent',\n",
    "    'createaccount': 'Create Account',\n",
    "    'deleteaccount': 'Delete Account',\n",
    "    'deliveryoptions': 'Delivery Options',\n",
    "    'deliveryperiod': 'Delivery Period',\n",
    "    'editaccount': 'Edit Account',\n",
    "    'getinvoice': 'Get Invoice',\n",
    "    'getrefund': 'Get Refund',\n",
    "    'newslettersubscription': 'Newsletter Subscription',\n",
    "    'paymentissue': 'Payment Issue',\n",
    "    'placeorder': 'Place Order',\n",
    "    'recoverpassword': 'Recover Password',\n",
    "    'registrationproblems': 'Registration Problems',\n",
    "    'review': 'Review',\n",
    "    'setupshippingaddress': 'Setup Shipping Address',\n",
    "    'switchaccount': 'Switch Account',\n",
    "    'trackorder': 'Track Order',\n",
    "    'trackrefund': 'Track Refund'\n",
    "}\n",
    "\n",
    "# Define FAQ vs Non-FAQ intent lists\n",
    "faq_intents = [\n",
    "    'getweather', 'searchcreativework', 'greeting', 'greetingresponse',\n",
    "    'courtesygreeting', 'courtesygreetingresponse', 'currenthumanquery',\n",
    "    'namequery', 'realnamequery', 'timequery', 'thanks', 'nottalking2u',\n",
    "    'understandquery', 'shutup', 'swearing', 'goodbye', 'courtesygoodbye',\n",
    "    'whoami', 'clever', 'gossip', 'jokes', 'podbaydoor', 'podbaydoorresponse',\n",
    "    'selfaware'\n",
    "]\n",
    "\n",
    "non_faq_intents = [\n",
    "    'playmusic', 'addtoplaylist', 'ratebook', 'searchscreeningevent',\n",
    "    'bookrestaurant', 'cancelorder', 'changeorder', 'changeshippingaddress',\n",
    "    'checkcancellationfee', 'checkinvoice', 'checkpaymentmethods',\n",
    "    'checkrefundpolicy', 'complaint', 'contactcustomerservice',\n",
    "    'contacthumanagent', 'createaccount', 'deleteaccount', 'deliveryoptions',\n",
    "    'deliveryperiod', 'editaccount', 'getinvoice', 'getrefund',\n",
    "    'newslettersubscription', 'paymentissue', 'placeorder', 'recoverpassword',\n",
    "    'registrationproblems', 'review', 'setupshippingaddress', 'switchaccount',\n",
    "    'trackorder', 'trackrefund'\n",
    "]\n",
    "\n",
    "################################################################################\n",
    "# 4. Core Functions\n",
    "################################################################################\n",
    "\n",
    "# 4.1 Intent Recognition\n",
    "def predict_intent(text):\n",
    "    inputs = intent_tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=64)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = intent_model(**inputs)\n",
    "    \n",
    "    predicted_label_idx = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    # Convert to actual label\n",
    "    intent_name = label_encoder.inverse_transform([predicted_label_idx])[0]\n",
    "    readable_intent = intent_label_mapping.get(intent_name, intent_name)\n",
    "    \n",
    "    # Determine if FAQ or Non-FAQ\n",
    "    if intent_name in faq_intents:\n",
    "        intent_type = \"FAQ\"\n",
    "    else:\n",
    "        intent_type = \"Non-FAQ\"\n",
    "    \n",
    "    return readable_intent, intent_type\n",
    "\n",
    "# 4.2 Sentiment Analysis\n",
    "def predict_sentiment(text):\n",
    "    encoding = sentiment_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=96\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = sentiment_model(**encoding)\n",
    "        probs = torch.softmax(output.logits, dim=1)\n",
    "        pred = torch.argmax(probs).item()\n",
    "    \n",
    "    # Assuming 0 = Negative, 1 = Positive. Adjust if your model is different.\n",
    "    return \"Positive\" if pred == 1 else \"Negative\"\n",
    "\n",
    "# 4.3 FAQ Answering\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spell = SpellChecker()\n",
    "\n",
    "def clean_question(text):\n",
    "    # Lowercase and remove punctuation\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "\n",
    "    # Correct typos\n",
    "    words = text.split()\n",
    "    corrected_words = [\n",
    "        spell.correction(word) if spell.correction(word) is not None else word\n",
    "        for word in words\n",
    "    ]\n",
    "    text = ' '.join(corrected_words)\n",
    "\n",
    "    # Lemmatize and remove stopwords\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def retrieve_answer(user_query, df, threshold=0.7):\n",
    "    cleaned_user_query = clean_question(user_query)\n",
    "    \n",
    "    # Encode query\n",
    "    query_embedding = faq_encoder.encode([cleaned_user_query])\n",
    "    \n",
    "    # Compute similarity\n",
    "    similarities = cosine_similarity(query_embedding, np.stack(df[\"embedding\"]))\n",
    "    best_match_idx = np.argmax(similarities)\n",
    "    best_score = similarities[0][best_match_idx]\n",
    "\n",
    "    if best_score >= threshold:\n",
    "        return df.iloc[best_match_idx][\"cleaned_answer\"]\n",
    "    else:\n",
    "        return \"Sorry, I couldn't find a relevant answer.\"\n",
    "\n",
    "# 4.4 AI Response Generation (for Non-FAQ)\n",
    "ai_template = \"\"\"\n",
    "You are a helpful customer support chatbot. The user says: \"{query}\"\n",
    "\n",
    "Please provide a concise and helpful response:\n",
    "\"\"\"\n",
    "ai_prompt = PromptTemplate(template=ai_template, input_variables=[\"query\"])\n",
    "ai_chain = LLMChain(llm=llm, prompt=ai_prompt)\n",
    "\n",
    "def generate_ai_response(user_query):\n",
    "    return ai_chain.run(query=user_query)\n",
    "\n",
    "# 4.5 Tone Adjustment\n",
    "tone_template = \"\"\"\n",
    "You are a helpful customer support chatbot.\n",
    "The user asked: {query}\n",
    "We have a raw response: {raw_answer}\n",
    "The user's sentiment is: {sentiment}\n",
    "\n",
    "Rewrite the raw response to match the user's sentiment:\n",
    "- If sentiment is \"Positive\", use a cheerful and friendly tone.\n",
    "- If sentiment is \"Negative\", use an empathetic and supportive tone.\n",
    "- If sentiment is \"Neutral\", use a neutral and professional tone.\n",
    "\n",
    "Final response:\n",
    "\"\"\"\n",
    "tone_prompt = PromptTemplate(\n",
    "    template=tone_template,\n",
    "    input_variables=[\"query\", \"raw_answer\", \"sentiment\"]\n",
    ")\n",
    "tone_chain = LLMChain(llm=llm, prompt=tone_prompt)\n",
    "\n",
    "def tone_adjust_response(user_query, raw_answer, sentiment):\n",
    "    return tone_chain.run(\n",
    "        query=user_query,\n",
    "        raw_answer=raw_answer,\n",
    "        sentiment=sentiment\n",
    "    )\n",
    "\n",
    "################################################################################\n",
    "# 5. Main End-to-End Function\n",
    "################################################################################\n",
    "\n",
    "def swiftassist_chatbot(user_query):\n",
    "    \"\"\"\n",
    "    1. Predict intent\n",
    "    2. Predict sentiment\n",
    "    3. If FAQ -> retrieve FAQ answer\n",
    "       Else -> AI response generation\n",
    "    4. Tone-adjust the answer using sentiment\n",
    "    5. Return final response + details\n",
    "    \"\"\"\n",
    "    # Step 1: Intent Recognition\n",
    "    predicted_intent, intent_type = predict_intent(user_query)\n",
    "    \n",
    "    # Step 2: Sentiment Analysis\n",
    "    sentiment = predict_sentiment(user_query)\n",
    "    \n",
    "    # Step 3: FAQ or Non-FAQ\n",
    "    if intent_type == \"FAQ\":\n",
    "        raw_answer = retrieve_answer(user_query, D_emb)\n",
    "    else:\n",
    "        raw_answer = generate_ai_response(user_query)\n",
    "    \n",
    "    # Step 4: Tone Adjustment\n",
    "    #   If your sentiment model only outputs \"Positive\" or \"Negative\",\n",
    "    #   you might want a fallback for \"Neutral\". Example:\n",
    "    if sentiment not in [\"Positive\", \"Negative\"]:\n",
    "        sentiment = \"Neutral\"\n",
    "    \n",
    "    final_response = tone_adjust_response(user_query, raw_answer, sentiment)\n",
    "    \n",
    "    # Step 5: Return or print\n",
    "    return {\n",
    "        \"Predicted Intent\": predicted_intent,\n",
    "        \"Intent Type\": intent_type,\n",
    "        \"Sentiment\": sentiment,\n",
    "        \"Final Response\": final_response.strip()\n",
    "    }\n",
    "\n"
   ],
   "id": "68f043451c374cc9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T15:05:57.956222Z",
     "start_time": "2025-03-22T15:05:54.673984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# 6. Example Usage\n",
    "################################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example user query\n",
    "    user_query = \"Hello, who are you? I'm a bit curious.\"\n",
    "\n",
    "    result = swiftassist_chatbot(user_query)\n",
    "\n",
    "    print(\"Predicted Intent:\", result[\"Predicted Intent\"])\n",
    "    print(\"Intent Type:\", result[\"Intent Type\"])\n",
    "    print(\"Sentiment:\", result[\"Sentiment\"])\n",
    "    print(\"Final Response:\", result[\"Final Response\"])\n"
   ],
   "id": "746846c5c56626f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Intent: Who Am I\n",
      "Intent Type: FAQ\n",
      "Sentiment: Positive\n",
      "Final Response: Hi there! I'm a friendly customer support chatbot here to help you with any questions you might have.  I'm still learning and growing, so while I couldn't quite understand your question about who I *am* philosophically (🤔), I'm ready to assist with anything else you need!  Just let me know! 😊\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd71bb75652048a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
